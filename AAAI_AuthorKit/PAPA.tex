%File: formatting-instruction.tex
\documentclass[letterpaper]{article}
% AAAI format packages
\usepackage{aaai}
\usepackage{times}
\usepackage{helvet}
\usepackage{courier}
% Additional packages
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{comment}
\newtheorem{defn}{Definition}
\newtheorem{lemma}{Lemma}
\newtheorem{thm}{Theorem}
\newtheorem{cor}{Corollary}
% END Additional packages
\frenchspacing
\setlength{\pdfpagewidth}{8.5in}
\setlength{\pdfpageheight}{11in}
\pdfinfo{
/Title (PAPA*: Path-Aware Parallel A*)
/Author (Aram Ebtekar, Mike Phillips, Sven Koenig, Maxim Likhachev)
/Keywords (weighted A* search, parallel algorithm, heuristic)
}
\setcounter{secnumdepth}{0}  
 \begin{document}
% The file aaai.sty is the style file for AAAI Press 
% proceedings, working notes, and technical reports.
%
\title{PAPA*: Path-Aware Parallel A*}
\author{Aram Ebtekar$^\dagger$ \and Mike Phillips$^\dagger$ \and Sven Koenig\thanks{University of Southern California, Los Angeles, CA 90089} \and Maxim Likhachev% <-this % stops a space
\thanks{Carnegie Mellon University, Pittsburgh, PA 15217}% <-this % stops a space
%
}
\author{AAAI 2015 Submission X}% anonymizer
\maketitle
\begin{abstract}
\begin{quote}
PAPA* is an anytime parallel heuristic search algorithm based on ARA* and PA*SE, which are in turn based on A*.
\end{quote}
\end{abstract}

\section{Fancy Stuff}

\begin{algorithm}
\caption{bound($s$)}
\label{alg:bound}
\begin{algorithmic}
\STATE $g_{front} := \infty$
\STATE $s' :=$ first node in $OPEN \cup BE$
\STATE $g_{back} := g(s) + f(s') - f(s) + (2\epsilon-w-1) c_l$
\WHILE{$g_{back} < g(s) \le g_{front}$}
\STATE $g_{front} := \min(g_{front},\;g_p(s') + \epsilon h(s',s))$
\STATE $s' :=$ node following $s'$ in $OPEN \cup BE$
\STATE $g_{back} := g(s) + f(s') - f(s) + (2\epsilon-w-1) c_l$
\ENDWHILE
\RETURN $\min(g_{front},\;g_{back})$
\end{algorithmic}
\end{algorithm}

\begin{algorithm}
\caption{PAPA*}
\label{alg:PAPA*}
\begin{algorithmic}
\WHILE{$g(s_{goal}) > bound(s_{goal})$}
\STATE remove an $s$ from $OPEN$ that has the smallest $f(s)$ among all states in $OPEN$ with $g(s) \le bound(s)$ and let $g_{bound} := bound(s)$
\IF{such an $s$ does not exist}
\STATE wait until $OPEN$ or $BE$ change
\STATE continue
\ENDIF
\STATE insert $s$ into $BE$
\STATE insert $s$ into $CLOSED$
\STATE $S := getSuccessors(s)$
\FORALL{$s' \in S$}
\STATE LOCK $s'$
\IF{$s'$ has not been generated yet}
\STATE $g(s') := g_p(s') := \infty$
\ENDIF
\STATE $g_p(s') = \min(g_p(s),\; g_{bound} + \epsilon c(s,s'))$
\IF {$g(s') > g(s) + c(s,s')$}
\STATE $g(s') = g(s) + c(s,s')$
\STATE $bp(s') = s$
\IF{$s' \in CLOSED$}
\STATE insert $s'$ in $FROZEN$
\ELSE
\STATE insert/update $s'$ in $OPEN$ with key $f(s')$
\ENDIF
\ENDIF
\STATE UNLOCK $s'$
\ENDFOR
\STATE remove $s$ from $BE$
\ENDWHILE
\end{algorithmic}
\end{algorithm}

\begin{algorithm}
\caption{main()}
\label{alg:main}
\begin{algorithmic}
\STATE $g(s_{start}) := 0$
\STATE $g(s_{goal}) := g_p(s_{goal}) := \infty$
\STATE $OPEN := BE := \emptyset$
\STATE $FROZEN := \{s_{start}\}$
\REPEAT
\STATE choose $\epsilon \in [1,\infty]$ and $w \in [0,\epsilon]$
\STATE $OPEN := OPEN \cup FROZEN$ with keys $f(s)$
\STATE $CLOSED := FROZEN := \emptyset$
\FORALL{$s\in OPEN$}
\STATE $g_p(s) := \epsilon g(s)$
\ENDFOR
\STATE run PAPA* on multiple threads in parallel
\UNTIL{path is good enough or planning time runs out}
\end{algorithmic}
\end{algorithm}

Keys are always computed by $f(s) = g(s) + wh(s,s_{goal})$, and we assume all edge costs are bounded below by $c_l$. $h$ must be consistent: $h(s,s') \le c(s,s')$ and $h(s,s') \le h(s,s'')+h(s'',s')$ for all $s,s',s''$. For most applications, we recommend using $w = \epsilon$. However, our analysis will show that using small $w$ yields strong parallelism guarantees. All operations on the data structures $OPEN,BE,CLOSED,FROZEN$ are assumed to be atomic, i.e. they are implicitly preceded and succeeded by synchronous locks and unlocks to the data structure, respectively. $\epsilon$ decreases between iterations of the main() loop.

\begin{lemma}
\label{lem:indep}
At all times, for all states $s,s' \ne s_{start}$:
\[g(s) + f(s') - f(s) + (2\epsilon-w-1) c_l \le g_p(s') + \epsilon h(s',s).\]
\end{lemma}

\begin{proof}
\begin{eqnarray*}
&&g(s) + f(s') - f(s) + (2\epsilon-w-1) c_l
\\&=& g(s') + w(h(s',s_{goal}) - h(s,s_{goal})) + (2\epsilon-w-1) c_l
\\&\le& g(s') + wh(s',s) + (2\epsilon-w-1) c_l
\\&\le& g(s') + \epsilon h(s',s) + (w-\epsilon) c_l + (2\epsilon-w-1) c_l
\\&=& g(s') + (\epsilon-1) c_l + \epsilon h(s',s)
\\&\le& g_p(s') + \epsilon h(s',s)
\end{eqnarray*}
\end{proof}

\begin{lemma}
\label{lem:bound}
$bound(s) \le \min_{s'\in OPEN \cup BE} g_p(s') + \epsilon h(s',s)$. Furthermore, $g(s) \le bound(s)$ iff $g(s) \le \min_{s'\in OPEN \cup BE} g_p(s') + \epsilon h(s',s)$.
\end{lemma}

\begin{proof}
By construction, $bound(s)$ is bounded above by $g_p(s') + \epsilon h(s',s)$ for states $s'$ which are checked in the loop. As for the remaining states $s' \in OPEN \cup BE$, the algorithm ensures that $bound(s) \le g(s) + f(s') - f(s) + (2\epsilon-w-1) c_l$ for these by using a minimum representative. By Lemma \ref{lem:indep}, it follows that
\[bound(s) \le \min_{s' \in OPEN \cup BE} g_p(s') + \epsilon h(s',s).\]

For the second part, note that the loop in $bound(s)$ terminates under only two conditions. Either $g(s) > g_{front}$, in which case we have $g(s) > g_p(s') + \epsilon h(s',s) \ge bound(s)$ for the $s'$ which began the final iteration; or $g(s) \le g_{back}$, in which case $g(s) \le bound(s)$ iff $g(s) \le g_{front}$ iff $g(s) \le g_p(s') + \epsilon h(s',s)$ for all $s' \in OPEN \cup BE$.
\end{proof}

\begin{lemma}
\label{lem:opt}
For every optimal path from $s_{start}$ to some $s\in OPEN$, every state $s'$ up to and including the first one in $OPEN \cup BE \cup FROZEN$ has $g(s') = g^*(s').$
\end{lemma}

\begin{proof}
We proceed by induction on time: noting the lemma holds right after $s_{start}$ is added to the open list, we show that it can never become false. Suppose for contradiction that it becomes false at some point. Since $g(s')$ never changes after achieving $g^*(s')$, it must be the case that the first state $s'$ along some optimal path to lie in $OPEN \cup BE \cup FROZEN$ has stopped being in this set. This can only happen by expanding $s'$ before its successor along the path. But then, the successor is added to $OPEN$ and its $g$-value is made optimal by the expansion of $s'$. Therefore, the invariant is maintained.
\end{proof}

\begin{thm}
\label{thm:subopt}
For all states $s$, $bound(s) \le \epsilon g^*(s)$. Hence, for all $s\in CLOSED$, $g(s) \le \epsilon g^*(s)$.
\end{thm}

\begin{proof}
We proceed by induction on the order in which states are expanded.

Fix an optimal path to $s$, and let $s'$ be the first node on it which is in $OPEN \cup BE$. Now, there are two cases to consider.

If $s'$ is one of the nodes which were originally transferred from $FROZEN$ to $OPEN$ in the current iteration of the main() loop, then $g(s') = g^*(s')$. Therefore,
\[g_p(s') \le \epsilon g(s') = \epsilon g^*(s').\]

Otherwise, let $s_p$ be the predecessor of $s'$ on the optimal path. Then $s_p \in CLOSED$ so, by the induction hypothesis, $g(s_p) \le \epsilon g^*(s_p)$. Therefore,
\[g_p(s') \le g(s_p) + \epsilon c(s_p,s') \le \epsilon(g^*(s_p) + c(s_p,s')) = \epsilon g^*(s').\]
In either case,
\[g_p(s') + \epsilon h(s',s) \le \epsilon\left(g^*(s') + c^*(s',s)\right) = \epsilon g^*(s).\]
Therefore, by Lemma \ref{lem:bound},
\[bound(s) \le \min_{s' \in OPEN \cup BE} g_p(s') + \epsilon h(s',s) \le \epsilon g^*(s).\]
\end{proof}

\begin{cor}
\label{cor:subopt}
At the end of a main() loop iteration, the path obtained by following the back-pointers $bp(\cdot)$ from $s_{goal}$ to $s_{start}$ is $\epsilon$-suboptimal.
\end{cor}

\begin{proof}
The termination condition of PAPA* implies $g(s_{goal}) \le bound(s_{goal})$. By construction, the path given by following back-pointers costs at most $g(s_{goal})$. The claim thus follows from Theorem \ref{thm:subopt}.
\end{proof}

\begin{thm}
\label{thm:depth}
If $w \le 1$, the parallel depth of checkless PAPA* is bounded above by
\[\min\left(\frac{\epsilon g^*(s_{goal})}{(1-w)c_l},\;
\frac{\left(\epsilon g^*(s_{goal})\right)^2 }{(4\epsilon-2w-2)c_l^2}\right).\]
\end{thm}

\begin{proof}
We prove the two bounds separately. For the first, note that if the lowest $f$-value is $f_{min}$, every state with $f$-value up to $f_{min} + (2\epsilon-w-1)c_l$ can simultaneously be expanded. Since $h$ is consistent, the successors' $f$-values is at least $f_{min} + (1-w)c_l$. Therefore, the depth is at most
\[\frac{\epsilon g^*(s_{goal})}{(1-w)c_l}\]

For the other bound, notice that since $f$-values never decrease along paths, once the minimum $f$-value in $OPEN$ surpasses $f_{min}$, from then on all nodes with $f$-value up to $f_{min} + (2\epsilon-w-1)c_l$ are always safe to expand. And during each iteration of the simultaneous expansions, the $g$-value of all such nodes increases by at least $c_l$. Since $g$ cannot exceed $f$, this continues for at most $(f_{min} + (2\epsilon-w-1)c_l) / c_l = f_{min}/c_l + 2\epsilon-w-1$ iterations, after which every node in $OPEN$ has $f$-value $\ge f_{min} + (2\epsilon-w-1)c_l$. Continuing this process until $f_{min}$ exceeds $\epsilon g^*(s_{goal})$, a bound on the total iteration count is:

$2\epsilon-w-1 + 2(2\epsilon-w-1) + 3(2\epsilon-w-1) + ... + \epsilon g^*(s_{goal})/c_l
\approxeq (\epsilon g^*(s_{goal})/c_l )^2 / ( 4\epsilon-2w-2 ).$
\end{proof}

\section{Edgewise Supobtimality}

Let $k(s)$ be the least number of edges used in a minimum-cost path to $s$ and fix $\delta > 0$. If $g_{front}$ and $g_{back}$ are each increased by $2\delta$, then by similar arguments to the proofs earlier in the paper, we find that, upon expanding $s$, $g(s) \le \epsilon g^*(s) + \delta k(s)$.

Here's an extension inspired by \cite{klein1997randomized}: suppose the mean edge cost $c_m$ along the optimal path is known to be much greater than the lower bound $c_l$. In such a case, the bound in Theorem \ref{thm:depth} scales poorly. To remedy the situation, we ``grow" the small edges, effectively running PAPA* with $c_l' = c_l + \delta$ and $c'(s,s') = \max(c(s,s'), c_l')$.

\begin{thm}
\label{thm:delta}
If the mean cost of the edges along the minimum-cost path to $s$ is at least $c_m$, then upon expansion, $g(s) \le \epsilon(1+\delta/c_m)g^*(s)$. Therefore, to get the same optimality factor as $\epsilon$, we can set $\delta = (\epsilon-1)c_m$.
\end{thm}

\begin{proof}
We assumed $c_m \le g^*(s) / k(s)$, so $k(s) \le g^*(s) / c_m$.
It follows from Lemma \ref{thm:subopt} that $g'(s) \le \epsilon g'^*(s) \le \epsilon(g^*(s) + \delta k(s)) \le \epsilon(1+\delta/c_m)g^*(s)$.
\end{proof}

\begin{cor}
\label{cor:delta}
If $w \le 1$, the parallel depth of checkless PAPA* can be improved to
\[\frac{\epsilon g^*(s_{goal})}{(1-w)(c_l+(\epsilon-1)c_m)}.\]
\end{cor}

\bibliographystyle{aaai}
\bibliography{PAPA}

\end{document}
